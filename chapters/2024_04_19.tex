 \chapter[The 19$^{\text{th}}$ of April 2024 -2D]{2D}

\begin{chapabstract}
	No meeting but notes, ideas and discussions
\end{chapabstract}


\minitoc

\section{Integral formulation of the 2D problem}

\subsection{Training}
\subsubsection{Integral evaluation}
For the integral computation of the loss during the training, no input is required as the only evaluation points for the space quantities are evaluated at the integration points that only depends on the mesh and the order of the elements. 

\Rqs{For the automatic differenciation to be available when computing the loss, the inverse mapping $\mathcal{M}^{-1}$ from the real coordinates to the reference coordinate is used when interpolating the displacement. That allows any derivative to be computed using the automated tools later in the loss. The strain could be directly be derived but that might be a limitation for most complex loss functions.}{The difference between evaluation and training are easily handled by calling the methods
\begin{itemize}
	\item \code{model.train()}
	\item \code{model.eval()}
	\end{itemize}}

\begin{equation}
	\begin{cases}
		\vect{x_g} = \sum\limits_{i = 1}^{N_e} N_i(\vect{\xi_g})\vect{x_i} \\
		\vect{u}\left(\vect{x_g}\right) =  \sum\limits_{i = 1}^{N_e} N_i\left(\underbrace{\mathcal{M}^{-1}\left(\vect{x_g}\right)}_{=\vect{\xi_g}}\right)\vect{u_i } \\[7pt]
		\text{det}\left(J\left(\vect{x_g}\right)\right) = \text{det}\left(\frac{\mathrm{d}\vect{\xi_g}}{\mathrm{d}\vect{x_g}}\right)
	\end{cases}
\end{equation}

\subsubsection{Multi-scale strategy}

In order to speed-up the convergence process the transfer learning capabilities of the HiDeNN framework (described in \cref{chap:Transfer_learning} for the parametric case) are used to spread global information from a coarse scale as an initialisation of a finer scale. Such a training merges the mesh convergence analysis with the computation of a solution at a lower cost, ensuring the quality of the final solution regarding discretisation error. 


The automation of the multi-scale training rely an a convergence criterion of the mesh's size. A first idea is to compute the value of the maximum strain of the last converged mesh and compare it to the value of the previous converged mesh. If stagnation is met then training is stopped otherwise a refinement is performed and the previous coarser solution is used to initialise the finer solution.

\paragraph{Conclusion} It works fine but doubling (is there a robust better choice?) the number of nodes every time quickly increases a lot the number of nodes. Should look at local refinement instead.

\subsubsection{Mesh r-adaptivity}


The iso-stress appears smoother with r-adaptivity as the chequerboard effect is less noticeable as illustrated in \cref{fig:r-adaptivity}

\begin{figure}
	\begin{subfigure}[t]{0.5\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Fixed_mesh_sigma_yy.png}
		\caption{$\sigm_{yy}$ stress component on the \\fixed initial mesh}
	\end{subfigure}
	\begin{subfigure}[t]{0.5\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Free_mesh_sigma_yy.png}
		\caption{$\sigm_{yy}$ stress component on the \\adapted mesh}
	\end{subfigure}  
	\caption{Influence of mesh adaptivity on the stress}
	\label{fig:r-adaptivity}
\end{figure}


\begin{itemize}
	\item For it to be very efficient we must find a way to do \textit{h-adaptivity}
	\item Instead of uniform refinements, use local refinement (Split T3 elements where the increase in density exceeds a threshold)
	\begin{itemize}
		\item If no recombination, should be fairly easy
	\end{itemize}
\end{itemize}

\subsection{Mesh h-adaptivity}

An idea would be to split the elements whose indexes $I_{ds}$ are

\begin{equation}
	I_{ds} = \argmax_{e}~\frac{\mathrm{d}}{\mathrm{d}t} \left[ \text{det}\left(J\left(x^e_g\right)\right)\right]
\end{equation}

\begin{itemize}
	\item If global refinement needed, set max element size as average current element size on the locally refined mesh.
\end{itemize}

\Rqs{That would allow to get rid of the ``Mesh initialisation'' difficulty during refinement if an external mesher is not called for the local refinements.}{
	\begin{itemize}
		\item Do we add nodes at every iterations or only if velocity of density changes exceeds a given threshold?
		\item Do we fix a threshold regarding the max ratio of jacobians above which a global refinement is made ?
	\end{itemize}}

\subsubsection{Refinement strategy}

\paragraph{Naive strategy} Local refinement performed by adding a node at the barycentre and split triangle into three new triangles. 

\begin{itemize}
	\item I thought that because the other nodes are somehow moving, refining only the inside of the element and not the edges would be OK but creating those long edges triangle very often lead to bad meshes that are not improving later
	\item For an unknown reason thenew point rarely cross the old element boundaries (which is good) but the do get squished quite often.
	\item We could:
	\begin{itemize}
		\item Keep this local refinement method
		\begin{itemize}
			\item Freeze mesh after refinement
			\item Find a regularisation
		\end{itemize}
			\item Consider splitting the edges 
				\begin{itemize}
				\item More challenging technically as it would not be local any more element-wise (hard to vectorise)
				\item Or it would mean allowing "hanging nodes"
				\item Difficulty: How to handle geometric boundary ? Re-meshing is necessary to incorporate the geometry
					\begin{itemize}
					\item Switch case if close to boundaries then add node at the barycentre
				\end{itemize}
			\end{itemize}
	\end{itemize}
\end{itemize}


\section{Stress admissibility}
\begin{wrapfigure}{r}{0.45\textwidth}
	\vspace{-60pt}
	\flushright
	\includegraphics[width=0.6\linewidth]{Figures/Omega.pdf}
	\caption{Reference problem}
	\label{fig:Body}
\end{wrapfigure}
%\begin{figure}
%	\includegraphics[width=\linewidth]{Figures/Omega.pdf}
%	\caption{Reference problem}
%	\label{fig:Body}
%\end{figure}
The solution is sought after as the pair $\left(\vect{u_{NN}},\sigm_{NN}\right) \in \mathcal{U}  \times \mathcal{S}$, with
\begin{equation}
	\begin{cases}
	\mathcal{U} = \left\{\vect{u} \; | \; \vect{u}\in \mathcal{H}^1\left(\Omega\right)\text{,} 
	\vect{u} = \vect{u}_d \text{ on } \partial \Omega_d \right\}, \\
		\mathcal{S} = \left\{\sigm \; | \; \sigm\in \mathcal{H}\left(\text{div}\right)\text{,} \text{\textbf{div}}\left(\sigm\right)+\vect{f_v} = \vect{0}\text{ and }
	\sigm\vect{n} = \vect{F}_d \text{ on } \partial \Omega_N \right\}, 
	\end{cases}
\end{equation}
by minimising a cost function 
\begin{equation*}
	\mathcal{L} = L^2\underbrace{\Vert \text{\textbf{div}}\left(\sigm_{NN}\right)+\vect{f}\Vert_2^2}_{\mathcal{L}_{\text{PDE}}} + \underbrace{ \Vert \sigm_{NN} - \ftensor{K}:\eps\left(\vect{u_{NN}}\right) \Vert^2_{2}}_{\mathcal{L}_{\text{const}}}
\end{equation*} consisting of a constitutive error term $\mathcal{L}_{\text{const}}$ and a PDE residual term $\mathcal{L}_{\text{PDE}}$.
\subsection{Constitutive error}
\paragraph{Definition}
In the mixed formulation, the interpolated stress $\sigm_{NN} \in \mathcal{H}\left(\text{div}\right)$ is divergence free while the displacement-derived stress $\sigm\left(\vect{u_{NN}}\right) \notin \mathcal{H}\left(\text{div}\right)$ is not as $\vect{u_{NN}}\in \mathcal{H}^1\left(\Omega\right)$ only. Static admissibility can only be weakly satisfied and the strong form of the equilibrium is not satisfied by the displacement field. The constitutive error
\begin{equation}
	\Psi\left(\vect{u_{NN}},\sigm_{NN}\right) = \frac{1}{2} \Vert \sigm_{NN} - \ftensor{K}:\eps\left(\vect{u_{NN}}\right) \Vert^2_{\ftensor{K}} \neq \frac{1}{2} \mathcal{L}_{\text{const}}
	\label{eq:EC}
\end{equation}
not being zero at convergence illustrates that idea. 
\Rq{If the constitutive term in the loss is computed using a MSE, it differs from the CRE computed with the energetic norm. In a technical aspect a difference lies in the fact that the size of the element is accounted for in via the jacobian of the elements in the intergal form while the sum of the MSE depends strongly on the sampling points where the error is estimated. If we assume that the sampling matches the integration points on the structure:
\begin{equation}
	\begin{cases}
			\mathcal{L}_{\text{const}} = \frac{1}{N_g} \sum_{i=1}^{N_g} \left(\matrice{\delta}\sigm\left(\vect{x_i}\right)\right)^2 \\
				2	\Psi\left(\vect{u_{NN}},\sigm_{NN}\right) = \sum_{i=1}^{N_g} \left(\matrice{\delta}\sigm\left(\vect{x_i}\right):\ftensor{K}:\matrice{\delta}\sigm\left(\vect{x_i}\right)\text{det}\left(J\left(x_i\right)\right)\omega_i\right),
	\end{cases}
\end{equation}
with $\matrice{\delta}\sigm = \sigm_{NN} - \ftensor{K}:\eps\left(\vect{u_{NN}}\right)$.
}

\paragraph{Decoupling of the two fields}

\begin{equation}
	\begin{split}
			2~\Psi\left(\vect{u},\sigm\right) & =  \intV \left(\sigm - \ftensor{K}:\eps\left(\vect{u}\right)\right) : \ftensor{K}^-{-1}:\left(\sigm - \ftensor{K}:\eps\left(\vect{u}\right)\right) \dV\\ 
			& = \underbrace{\intV \sigm: \ftensor{K}^{-1}: \sigm \dV}_{2U\left(\sigm\right)} + \underbrace{\intV \eps\left(\vect{u}\right):\ftensor{K}:\eps\left(\vect{u}\right) \dV}_{2U\left(\vect{u}\right)}+ 2\intV\sigm:\eps\left(\vect{u}\right)\dV\\
			& = 2~ U\left(\sigm\right) +2~ U\left(\vect{u}\right) - 2\intV\sigm:\eps\left(\vect{u}\right)\dV.\\
	\end{split}
\end{equation}
If we then inject the equilibrium 
\begin{equation}
	\intV\sigm:\eps\left(\vect{u}\right)~\dV = \intS \left(\sigm\vect{n}\right) \cdot \vect{u_d}~\dS +  \intS \vect{F_d}\cdot \vect{u} ~\dS +\intV \vect{f_v}\cdot\vect{u}~\dV,
\end{equation}
in the previous results the constitutive error reads 
\begin{equation}
		\begin{split}
			\Psi\left(\vect{u},\sigm\right)  & = \underbrace{U\left(\sigm\right) - \intSd \left(\sigm\vect{n}\right) \cdot \vect{u_d}~\dS }_{E_p\left(\sigm\right)} +\underbrace{U\left(\vect{u}\right) -  \intSn \vect{F_d}\cdot \vect{u} ~\dS -\intV \vect{f_v}\cdot\vect{u}~\dV}_{E_p\left(\vect{u}\right)}.\\
			& =E_p\left(\sigm\right)+E_p\left(\vect{u}\right).
		\end{split}
\end{equation}

Therefore, minimising the constitutive error consists in finding 

\begin{equation}
	\left(\vect{u_{NN}},\sigm_{NN}\right) = \argmin_{\vect{u}\in \mathcal{U}, \sigm \in \mathcal{S}} \left(\Psi\left(\vect{u},\sigm\right)\right) =  \left(\argmin_{\vect{u}\in \mathcal{U}}E_p\left(\vect{u}\right),\argmin_{\sigm\in \mathcal{S}}E_p\left(\sigm\right)\right),
\end{equation}
\Rq{The two decoupled optimisation problems can be solved with two smaller optimisers as opposed to using one big optimiser.}
This decoupled statement does not hold with the $\mathcal{L}^2$-norm used in the actual loss or without using the equilibrium.



\Rqs{Solving the displacement problem is \textcolor{accentcolor}{\textbf{exactly}} the same as minimising the integral loss. Then to get an admissible stress the idea is to solve the stress related minimisation problem (second constitutive problem + PDE term) that leads to a stress that is statically admissible. Before decoupling (which might be harder in a non-linear case), the problem reads:
\begin{equation}
	\left(\vect{u_{NN}},\sigm_{NN}\right) = \argmin_{\vect{u}\in \mathcal{U}, \sigm \in \mathcal{H}\left(\text{div}\right)} \left(\Psi\left(\vect{u},\sigm\right)+\mathcal{L}_{\text{PDE}}\right) 
		\label{eq:coupledMixedmini}
\end{equation}
and after decoupling the problem becomes:
\begin{equation}
	\begin{split}
		\vect{u_{NN}} & = \argmin_{\vect{u}\in \mathcal{U}}E_p\left(\vect{u}\right) \\ 
		\sigm_{NN} & =  \argmin_{\sigm \in \mathcal{H}\left(\text{div}\right)} E_p\left(\sigm\right) + \mathcal{L}_{\text{PDE}},
	\end{split}
	\label{eq:decoupledMixedmini}
\end{equation}
the first equation of \cref{eq:decoupledMixedmini} being the exact same as the one in the intergal formulation.}{In \cref{eq:coupledMixedmini}, a question remains: does it make sense to compute $$\sigm - \ftensor{K}:\eps\left(\vect{u}\right)$$ with $\sigm \in \mathcal{H}\left(\text{div}\right)$ and $\left(\ftensor{K}:\eps\left(\vect{u}\right)\right) \in \mathcal{L}^2\left(\Omega\right)$. I would assume that yes and that the discrepencies account for the discretisation error.}

\paragraph{Partial conclusion} An idea would at least be to use a proper integral instead of the MSE to get rid of the arbitrary choice of sampling points and the dependence to the node density and so on. 

	
